{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d14c333",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be334ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da8c53",
   "metadata": {},
   "source": [
    "# Importing and Augmenting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    brightness_range = [0.3, 0.9],\n",
    "    shear_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1./255,\n",
    "validation_split = 0.2)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"/Gesture\",\n",
    "    target_size = (150, 150),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    subset = 'training')\n",
    "validation_data = train_datagen.flow_from_directory(\n",
    "    \"/Gesture\",\n",
    "    target_size = (150, 150),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    \"/Gesture\",\n",
    "    target_size = (150, 150),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'binary',\n",
    "    batch_size = 32,\n",
    "    shuffle = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc4eea",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(2, 2, figsize = (20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_data)\n",
    "plotImages(imgs)\n",
    "print(labels[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee562",
   "metadata": {},
   "source": [
    "# Fine-tuning a Pre-Trained Model (MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5 \\\n",
    "    -O /tmp/mobilenet_1_0_224_tf_no_top.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea661f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "local_weights_file = '/tmp/mobilenet_1_0_224_tf_no_top.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e468c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pre_trained_model(local_weights_file):\n",
    "    pre_trained_model = MobileNet(input_shape = (150, 150, 3), include_top = False, weights = None) \n",
    "    pre_trained_model.load_weights(local_weights_file)\n",
    "    \n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = create_pre_trained_model(local_weights_file)\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eed9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_desired_layer = pre_trained_model.get_layer('conv_pw_13_relu')\n",
    "last_output = last_desired_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_model(pre_trained_model, last_output):\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    x = tf.keras.layers.Dense(100, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(4, activation = 'softmax')(x)  \n",
    "    \n",
    "    model = tf.keras.Model(inputs = pre_trained_model.input, outputs = x)\n",
    "    model.compile(optimizer = \"adam\", loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9db1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_final_model(pre_trained_model, last_output)\n",
    "history = model.fit(x = train_data, validation_data = validation_data, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'ro--', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'bo--', label = 'Validation Loss')\n",
    "plt.title('Loss Curve', fontweight = \"bold\")\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'ro--', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'bo--', label = 'Validation Accuracy')\n",
    "plt.title('Accuracy', fontweight = \"bold\")\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data.labels\n",
    "y_prob = model.predict(test_data)\n",
    "y_pred = np.argmax(y_prob, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "sns.set_style(\"white\")\n",
    "c_m = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "labels = test_data.class_indices.keys()\n",
    "display_c_m = ConfusionMatrixDisplay(c_m, display_labels = labels)\n",
    "display_c_m.plot(cmap = 'Blues')\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.title('Confusion Matrix', fontsize = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268bb4e",
   "metadata": {},
   "source": [
    "# Testing Model on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def prepare_image(file):\n",
    "    img = image.load_img(file, target_size = (150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis = 0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e178e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"Path to image file\", width=500,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95666d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_image = prepare_image(\"Path to image file\")\n",
    "predictions = model.predict(preprocessed_image)\n",
    "print(np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40295722",
   "metadata": {},
   "source": [
    "# Saving Model Weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17691b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_model_arch.json', 'w') as f:\n",
    "    json.dump(model.to_json(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
